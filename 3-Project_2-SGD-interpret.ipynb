{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outside-helen",
   "metadata": {},
   "source": [
    "# Project 2: What kind of wine is this?\n",
    "## SGD route 3/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "korean-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-sigma",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "vocal-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"s3://ling583/wine-train.parquet\", storage_options={\"anon\": True})\n",
    "test = pd.read_parquet(\"s3://ling583/wine-test.parquet\", storage_options={\"anon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "negative-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "from sklearn.metrics import classification_report, f1_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "earlier-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = cloudpickle.load(open(\"sgd.model\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "physical-robinson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.69      0.83      0.75      7558\n",
      "        Chardonnay       0.82      0.85      0.84      4861\n",
      "            Merlot       0.82      0.33      0.48      1381\n",
      "        Pinot Noir       0.77      0.87      0.82      9618\n",
      "          Riesling       0.80      0.79      0.80      2421\n",
      "   Sauvignon Blanc       0.84      0.66      0.74      1278\n",
      "             Syrah       0.75      0.54      0.63      3426\n",
      "         Zinfandel       0.86      0.51      0.64      2082\n",
      "\n",
      "          accuracy                           0.76     32625\n",
      "         macro avg       0.80      0.67      0.71     32625\n",
      "      weighted avg       0.77      0.76      0.76     32625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = sgd.predict(test[\"review_text\"])\n",
    "print(classification_report(test[\"wine_variant\"], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-jefferson",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "strange-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sgd.named_steps['sgdclassifier'].classes_\n",
    "scores = sgd.decision_function(test[\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "forty-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cabernet Sauvignon', 'Chardonnay', 'Merlot', 'Pinot Noir',\n",
       "       'Riesling', 'Sauvignon Blanc', 'Syrah', 'Zinfandel'], dtype='<U18')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "rotary-eight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91421716, -0.59153672, -1.18795756, -1.30082701, -1.30191762,\n",
       "       -1.22055674, -1.1937916 , -1.2754422 ])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0,:]\n",
    "# The first entry, looks like it was classified as Chardonnay since that has the highest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "super-arabic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chardonnay'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at what the data source has it tagged as \n",
    "test['wine_variant'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "emerging-empty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hmmm. i have mixed emotions about this wine. on the one hand, i like it's minerality, but on the other, i think the acid is a bit whacked. on the one hand, it's a nice combo of fruit, but it has a funky finish. in the end, i wouldn't purchase it again.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['review_text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "relevant-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = scores.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "multiple-bridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5915367229888091"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "strategic-western",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30003"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The instance that has the highest score in the whole dataset\n",
    "highest.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "comfortable-newton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.24274893, -7.76634215, -1.88980817, 11.13470105, -4.51810363,\n",
       "       -4.27573661, -5.29510457, -2.59328838])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the scores for that highest scoring article; the most solidly in one category\n",
    "scores[30003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "designed-leisure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pinot Noir'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what category was that wine?\n",
    "test['wine_variant'].iloc[30003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "polyphonic-candy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this to me is a very pleasant, somewhat innocuous Pinot. Beautiful clear cherry colour, intense typical pinot nose of strawberry and red cherry, a little candied, and not giving up any pinot \"funk\". Palate is medium bodied for a pinot, lots of sweet cherry and strawberry fruit, maybe a little raspberry, nice acidity and low tannins, but lacking much complexity or \"wow\". Solid.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the review_text to see what made it score that high for that category\n",
    "test['review_text'].iloc[30003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "assumed-ridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15256"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the article where the highest value within the article is the lowest for that category\n",
    "highest.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "alike-thursday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.03386903, -1.21963577, -1.13820297, -1.18544596, -1.81132635,\n",
       "       -1.94491078, -1.38953799, -1.21904177])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like we assigned it to the Merlot category\n",
    "scores[10441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "collective-butterfly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Syrah'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is actually a Syrah\n",
    "test['wine_variant'].iloc[10441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "olympic-profit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Black fruit, very spicy, a certain sharpness; full, rounded, almost sweet on the attack, good fruit, vanilla, good weight, attractive but a bit heavy; good length, slightly edgy. Not a perfect bottle?'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['review_text'].iloc[10441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "interpreted-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.91421716 -0.59153672 -1.18795756 -1.30082701 -1.30191762 -1.22055674\n",
      "  -1.1937916  -1.2754422 ]\n",
      " [-1.85955469 -2.18956274 -1.15189218 -1.46690088 -2.59268997  0.63932941\n",
      "   0.71990302 -1.75302928]\n",
      " [-1.15436242 -1.98191743 -1.13756684  1.05110735 -1.75461611 -1.938044\n",
      "  -1.8747448  -1.28005751]\n",
      " [-1.56183083 -4.55272211 -1.21702344  1.38560418 -3.87471479 -2.47826185\n",
      "  -1.66635545 -0.98370125]\n",
      " [-3.85156343 -1.98670387 -1.43443435 -4.28874008 -2.067764   -1.92686402\n",
      "  -2.98513302  3.94012131]]\n"
     ]
    }
   ],
   "source": [
    "# Each row is a single test example, columns are the 4 classes\n",
    "print(scores[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fallen-estonia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30191762, -1.30082701, -1.2754422 , -1.22055674, -1.1937916 ,\n",
       "        -1.18795756, -0.91421716, -0.59153672],\n",
       "       [-2.59268997, -2.18956274, -1.85955469, -1.75302928, -1.46690088,\n",
       "        -1.15189218,  0.63932941,  0.71990302],\n",
       "       [-1.98191743, -1.938044  , -1.8747448 , -1.75461611, -1.28005751,\n",
       "        -1.15436242, -1.13756684,  1.05110735],\n",
       "       [-4.55272211, -3.87471479, -2.47826185, -1.66635545, -1.56183083,\n",
       "        -1.21702344, -0.98370125,  1.38560418],\n",
       "       [-4.28874008, -3.85156343, -2.98513302, -2.067764  , -1.98670387,\n",
       "        -1.92686402, -1.43443435,  3.94012131]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to see how close the highest and second highest scores are for each instance. Start by sorting the arrays\n",
    "# The issue here is that we lose the context of what score is associated to what category\n",
    "scores.sort(axis=1)\n",
    "scores[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "disciplinary-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the margins for the scores, That is the difference betwen the top and second score\n",
    "margin = scores[:,3]-scores[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "advised-colon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.7959465899108884, 3.1374356106450563e-06)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin.max(), margin.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "painted-marsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.70      0.80      0.75       473\n",
      "        Chardonnay       0.88      0.94      0.91        65\n",
      "            Merlot       0.70      0.16      0.26        86\n",
      "        Pinot Noir       0.66      0.85      0.74       436\n",
      "          Riesling       0.88      0.82      0.85        17\n",
      "   Sauvignon Blanc       0.85      0.74      0.79        23\n",
      "             Syrah       0.67      0.45      0.54       186\n",
      "         Zinfandel       0.88      0.34      0.49       108\n",
      "\n",
      "          accuracy                           0.70      1394\n",
      "         macro avg       0.78      0.64      0.67      1394\n",
      "      weighted avg       0.71      0.70      0.68      1394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We just want to see those where the margin is large\n",
    "minmarg = 1.06\n",
    "print(classification_report(test[\"wine_variant\"][margin > minmarg], predicted[margin > minmarg]))\n",
    "\n",
    "# The only way to break a Macro avg F-1 score over 0.85 is to exclude all but the one review with the highest margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "crucial-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "collectible-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresh = np.linspace(-2, 3, 50)\n",
    "x = [100*(1-sum(margin > t)/len(margin)) for t in thresh]\n",
    "y = [f1_score(test[\"wine_variant\"][margin > t], predicted[margin > t], average=\"macro\") for t in thresh]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('% Unknowns')\n",
    "plt.ylabel('F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "miniature-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Cabernet Sauvignon       0.63      0.80      0.71        30\n",
      "            Merlot       0.00      0.00      0.00         9\n",
      "        Pinot Noir       0.68      0.88      0.77        43\n",
      "          Riesling       1.00      1.00      1.00         2\n",
      "   Sauvignon Blanc       1.00      1.00      1.00         1\n",
      "             Syrah       0.67      0.50      0.57        12\n",
      "         Zinfandel       1.00      0.10      0.18        10\n",
      "\n",
      "          accuracy                           0.67       107\n",
      "         macro avg       0.71      0.61      0.60       107\n",
      "      weighted avg       0.65      0.67      0.62       107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test[\"wine_variant\"][margin > 1.75], predicted[margin > 1.75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-selection",
   "metadata": {},
   "source": [
    "**TO DO:** Summarize your results for this section. What could we do if we wanted to make label as many examples as possible while still keeping F1 above 0.99?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-asthma",
   "metadata": {},
   "source": [
    "The article that had the highest category score in this model conveniently had very low scores for the other 3 categories with a margin of about 7.79. When keeping only those articles with a margin greater than 5, there was an accuracy of 100% but we only return 93 articles or about 1.9% of all articles. When dropping the margin to 1.75, that netted us 3772 articles or about 79% of the total while keeping 99% accuracy.\n",
    "\n",
    "If we wanted to keep our F1 above 99% while maximizing our supporting articles, we could adjust the minimum margin required until it meets our needs. GVIO is the category that gives us the most trouble with this, thus pushing our minimum margin higher and our supporting articles lower. At minimum margin 2.2, all categories are at 1.00 F1 score except for GVIO which is at 0.99. GVIO doesn't reach F1 1.00 until minimum margin of 4.0. \n",
    "\n",
    "With the minimum margin at 2.2 we get 3145 supporting articles while at 4.0 (which we need in order to get GVIO to F1 1.00) we only get 482 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"margin > 2.2\\n\", classification_report(test[\"wine_variant\"][margin > 2.2], predicted[margin > 2.2])) # optimal for all but GVIO\n",
    "print()\n",
    "print(\"margin > 3.9\\n\",classification_report(test[\"wine_variant\"][margin > 3.9], predicted[margin > 3.9])) # to show that GVIO is still at 0.99\n",
    "print()\n",
    "print(\"margin > 4.0\\n\",classification_report(test[\"wine_variant\"][margin > 4], predicted[margin > 4])) # optimal for all categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-picnic",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "complimentary-video",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Cabernet Sauvignon', 'Chardonnay', 'Merlot', 'Pinot Noir',\n",
       "        'Riesling', 'Sauvignon Blanc', 'Syrah', 'Zinfandel'], dtype='<U18'),\n",
       " array([[ 1.16482924, -0.55363625, -0.25354167, ...,  0.        ,\n",
       "         -0.1048644 ,  0.        ],\n",
       "        [-0.08407375, -0.31999472,  0.00631175, ...,  0.26560864,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.14787126, -0.04511793,  0.01095268, ...,  0.        ,\n",
       "          0.18685405,  0.        ],\n",
       "        ...,\n",
       "        [-0.19029645, -0.13281826,  0.32686988, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.21091609,  0.43103112,  0.09219502, ...,  0.12213975,\n",
       "         -0.23696212, -0.09053757],\n",
       "        [-0.10272099,  0.33217593,  0.01105158, ...,  0.        ,\n",
       "         -0.01911391,  0.        ]]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = sgd.named_steps['sgdclassifier'].coef_\n",
    "labels, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "stock-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 15214)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "gross-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sgd.named_steps['countvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fundamental-roman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2092"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef[0,:].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "individual-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.250273793323963"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef[0,2092]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "taken-supplement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cab'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[2092]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-spanking",
   "metadata": {},
   "source": [
    "This means that for the GJOB category, each occurance of the word \"jobs\" gives a weight of 4.522631071356675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "increasing-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabernet Sauvignon\n",
      "  cab             13.250\n",
      "  cabernet        11.977\n",
      "  cabs             8.917\n",
      "  cassis           8.090\n",
      "  bordeaux         5.489\n",
      "  currant          5.310\n",
      "  napa             5.308\n",
      "  tannins          4.821\n",
      "  bell             4.530\n",
      "  caymus           4.456\n",
      "  chard           -3.717\n",
      "  zins            -3.898\n",
      "  pinots          -4.034\n",
      "  merlots         -4.240\n",
      "  chardonnay      -4.357\n",
      "  zinfandel       -4.688\n",
      "  burgundy        -4.729\n",
      "  zin             -7.275\n",
      "  syrah           -8.293\n",
      "  pinot           -9.024\n",
      "\n",
      "Chardonnay\n",
      "  chardonnay      11.614\n",
      "  chard            9.505\n",
      "  chablis          8.474\n",
      "  buttery          6.714\n",
      "  chards           6.555\n",
      "  butter           6.479\n",
      "  chardonnays      5.927\n",
      "  meursault        5.880\n",
      "  butterscotch     4.928\n",
      "  premox           4.830\n",
      "  cab             -4.165\n",
      "  dark            -4.207\n",
      "  cherries        -4.214\n",
      "  sb              -4.479\n",
      "  red             -4.724\n",
      "  pinot           -4.839\n",
      "  sauvignon       -5.157\n",
      "  riesling        -6.076\n",
      "  tannins         -6.117\n",
      "  petrol          -6.160\n",
      "\n",
      "Merlot\n",
      "  merlot          12.576\n",
      "  merlots          7.332\n",
      "  havens           1.870\n",
      "  paloma           1.560\n",
      "  pomerol          0.738\n",
      "  januik           0.605\n",
      "  li               0.603\n",
      "  bwc              0.588\n",
      "  tradition        0.579\n",
      "  trough           0.576\n",
      "  noir            -0.831\n",
      "  cab             -0.938\n",
      "  franc           -0.988\n",
      "  malbec          -1.015\n",
      "  petit           -1.077\n",
      "  cabs            -1.085\n",
      "  syrah           -1.257\n",
      "  verdot          -1.482\n",
      "  pinot           -1.752\n",
      "  sauvignon       -2.793\n",
      "\n",
      "Pinot Noir\n",
      "  pinot           17.376\n",
      "  pinots           9.358\n",
      "  pn               8.220\n",
      "  burgundy         6.677\n",
      "  cherry           6.395\n",
      "  cola             5.838\n",
      "  strawberry       5.648\n",
      "  vosne            5.261\n",
      "  strawberries     5.247\n",
      "  kb               5.001\n",
      "  zinfandel       -4.563\n",
      "  lemon           -4.772\n",
      "  yellow          -5.013\n",
      "  cassis          -5.049\n",
      "  white           -5.220\n",
      "  chardonnay      -5.532\n",
      "  cabernet        -6.162\n",
      "  syrah           -6.602\n",
      "  merlot          -6.770\n",
      "  cab             -8.150\n",
      "\n",
      "Riesling\n",
      "  riesling        10.632\n",
      "  petrol           8.581\n",
      "  rieslings        6.932\n",
      "  kabinett         6.030\n",
      "  auslese          5.259\n",
      "  reisling         5.003\n",
      "  spatlese         4.996\n",
      "  mosel            4.862\n",
      "  diesel           4.710\n",
      "  kerosene         4.697\n",
      "  buttery         -2.941\n",
      "  dark            -2.988\n",
      "  burgundy        -2.990\n",
      "  pinot           -3.185\n",
      "  vanilla         -3.295\n",
      "  cherry          -3.320\n",
      "  sb              -3.772\n",
      "  chablis         -3.843\n",
      "  tannins         -4.453\n",
      "  chardonnay      -4.803\n",
      "\n",
      "Sauvignon Blanc\n",
      "  sb               8.035\n",
      "  sauvignon        5.907\n",
      "  sancerre         5.782\n",
      "  gooseberry       5.054\n",
      "  grass            4.922\n",
      "  sbs              4.066\n",
      "  grassy           4.063\n",
      "  grassiness       4.008\n",
      "  sauv             3.913\n",
      "  gooseberries     3.816\n",
      "  petrol          -2.046\n",
      "  red             -2.177\n",
      "  strawberry      -2.192\n",
      "  cherry          -2.206\n",
      "  de              -2.271\n",
      "  pinot           -2.645\n",
      "  cab             -3.003\n",
      "  riesling        -3.046\n",
      "  chard           -3.152\n",
      "  chardonnay      -3.685\n",
      "\n",
      "Syrah\n",
      "  syrah           13.360\n",
      "  syrahs           8.255\n",
      "  rhone            6.423\n",
      "  hermitage        5.978\n",
      "  bacon            5.717\n",
      "  rotie            5.614\n",
      "  cornas           5.333\n",
      "  pax              5.264\n",
      "  cayuse           4.913\n",
      "  chave            4.856\n",
      "  zins            -2.259\n",
      "  cabs            -2.323\n",
      "  pn              -2.328\n",
      "  burgundy        -2.416\n",
      "  pinots          -2.629\n",
      "  zinfandel       -3.183\n",
      "  merlot          -3.518\n",
      "  cabernet        -4.015\n",
      "  zin             -4.537\n",
      "  cab             -4.873\n",
      "\n",
      "Zinfandel\n",
      "  zin             13.432\n",
      "  zinfandel        9.667\n",
      "  zins             9.387\n",
      "  turley           7.877\n",
      "  zinfandels       5.655\n",
      "  turleys          4.614\n",
      "  rosenblum        3.192\n",
      "  zinberry         2.970\n",
      "  seghesio         2.768\n",
      "  ravenswood       2.179\n",
      "  bell            -0.792\n",
      "  cabs            -0.847\n",
      "  chardonnay      -0.945\n",
      "  pn              -1.021\n",
      "  pinots          -1.388\n",
      "  syrahs          -1.396\n",
      "  cabernet        -1.552\n",
      "  merlot          -1.659\n",
      "  syrah           -2.239\n",
      "  cab             -2.797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranked = np.argsort(coef, axis=1)\n",
    "for i, label in enumerate(labels):\n",
    "    print(label)\n",
    "    for j in concat([range(-1, -11, -1), range(10, 0, -1)]):\n",
    "        print(f'  {vocab[ranked[i,j]]:15s} {coef[i, ranked[i,j]]:6.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "commercial-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kwic import kwic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "intended-comfort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>894</td>                      <td style=\"text-align:right;white-space:nowrap\"> nice wine. Leans more towards some blacker fruits than I usually get with </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\">'s but still very fresh and bright. Some moderate tannin, but a pure pleasu</td></tr><tr><td>1755</td>                      <td style=\"text-align:right;white-space:nowrap\">pen for business now. I am always amazed at how good these base bottles of </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\"> are...a real credit to the Officer/Maddox team.                           </td></tr><tr><td>2428</td>                      <td style=\"text-align:right;white-space:nowrap\">             Big, forceful wine that lacked the balance I normally feel in </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\">. Almost metallic backbone and loads of fruit, brambles, and cocoa notes. G</td></tr><tr><td>2682</td>                      <td style=\"text-align:right;white-space:nowrap\">d extraction, with a touch of heat. Finish is shorter than most of the the </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\"> zins. Enjoyable, but not to the level of most of his zins.                </td></tr><tr><td>3128</td>                      <td style=\"text-align:right;white-space:nowrap\">fruit, just enough spice. Too bad it was my last bottle. Drank alongside a </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\"> 2008 Dry Creek Valley Zinfandel - also quite good, but not in the same lea</td></tr><tr><td>3128</td>                      <td style=\"text-align:right;white-space:nowrap\">. Wife and I tried to keep this bottle to ourselves. Can't wait to get the </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\"> fall release order form.                                                  </td></tr><tr><td>5343</td>                      <td style=\"text-align:right;white-space:nowrap\">                                                                    A rare </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\"> that I didn't really enjoy. Must have been an \"off\" bottle since everyone </td></tr><tr><td>5505</td>                      <td style=\"text-align:right;white-space:nowrap\">ering\". Finished 5th (my 2nd place) against some pretty good zins: Another </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\">, Valdez, Turley, and Green and Red Child Mills.  I would recommend decanti</td></tr><tr><td>5573</td>                      <td style=\"text-align:right;white-space:nowrap\">ntinue to evolve and improve for a couple of years or more.  James Berry + </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\"> + a good vintage = YUMMY!                                                 </td></tr><tr><td>6549</td>                      <td style=\"text-align:right;white-space:nowrap\">hat matter Nalle, even though it isn't OTT and has some structure, and NOT </td>                      <td style=\"text-align:center;white-space:nowrap\">Carlisle</td>                      <td style=\"text-align:left;white-space:nowrap\">'s comprehensive package, and thus not quite that good a QPR) and in terms </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwic('carlisle', train['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "mineral-graduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>461</td>                      <td style=\"text-align:right;white-space:nowrap\">                                        Very strange, I liked this wine in </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> the first time, but it tasted like a Zinfandelish Cab. Definite hints of Z</td></tr><tr><td>1767</td>                      <td style=\"text-align:right;white-space:nowrap\">well integrated into the spicy red fruit. Reminds me of some of the better </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> zins I've tried.                                                          </td></tr><tr><td>2244</td>                      <td style=\"text-align:right;white-space:nowrap\">ses dark cherries, alcohol, oak chips, charcoal and tar in an almost jammy </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> style but stops short of this. Finish is full of cherries and brambles. Ve</td></tr><tr><td>2606</td>                      <td style=\"text-align:right;white-space:nowrap\">                                                                   A tasty </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> Zin- not too big or overpowering with the fruit- Alc in check as well. The</td></tr><tr><td>4519</td>                      <td style=\"text-align:right;white-space:nowrap\">                              Nice, not the fruit bomb I am used to from a </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> winery but believe the grapes are from Napa which would make perfect sense</td></tr><tr><td>6628</td>                      <td style=\"text-align:right;white-space:nowrap\">e been to the winery and really like this Zin. We have had others from the </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> area and this is still our favorite. Great price. Very drinkable now with </td></tr><tr><td>7458</td>                      <td style=\"text-align:right;white-space:nowrap\">    This wine is made from 80 - 100 year-old vines sourced from Oakley and </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> vineyard and spends 9 months in American oak. Medium red/purple color. At </td></tr><tr><td>8834</td>                      <td style=\"text-align:right;white-space:nowrap\">in, plenty of acid. Hot in the finish. Not nearly as big as we expect from </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\">, but better for it. Poor value at $52 direct with shipping, but very good </td></tr><tr><td>10629</td>                      <td style=\"text-align:right;white-space:nowrap\">d - fully loaded, ready to go. Not as good as Deerfield Ranchs' Zinfandel, </td>                      <td style=\"text-align:center;white-space:nowrap\">Lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> Zins, or Paso Robles zins, but this wine is right under those. The cork po</td></tr><tr><td>10629</td>                      <td style=\"text-align:right;white-space:nowrap\">t was gone. This is not the thickest zin that you would see from a paso or </td>                      <td style=\"text-align:center;white-space:nowrap\">lodi</td>                      <td style=\"text-align:left;white-space:nowrap\"> zin, but then again I was not expecting that given its origin in Lake Coun</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwic('lodi', train['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-affiliate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
